{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-1.30.1-py3-none-any.whl (17.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.17.3 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (2.30.0)\n",
      "Collecting cloudpickle<3\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting alembic<2\n",
      "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<2 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (1.3.5)\n",
      "Requirement already satisfied: numpy<2 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (1.21.6)\n",
      "Requirement already satisfied: entrypoints<1 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (0.4)\n",
      "Collecting Flask<3\n",
      "  Downloading Flask-2.2.5-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<2 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (1.7.3)\n",
      "Requirement already satisfied: packaging<22 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (21.3)\n",
      "Collecting gunicorn<21\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy<2,>=1.4.0\n",
      "  Downloading SQLAlchemy-1.4.48-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prometheus-flask-exporter<1\n",
      "  Downloading prometheus_flask_exporter-0.22.4-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: pytz<2023 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from mlflow) (2022.4)\n",
      "Collecting pyyaml<7,>=5.1\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.1.2-py3-none-any.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting querystring-parser<2\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
      "  Using cached importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from alembic<2->mlflow) (4.4.0)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Collecting urllib3<2.0.0,>=1.26.7\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.5.2-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=3.0 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from Flask<3->mlflow) (3.1.2)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from gunicorn<21->mlflow) (63.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from packaging<22->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from pandas<2->mlflow) (2.8.2)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.17.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from requests<3,>=2.17.3->mlflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from requests<3,>=2.17.3->mlflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (566 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/mle-dev/lib/python3.7/site-packages (from Jinja2>=3.0->Flask<3->mlflow) (2.1.2)\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143860 sha256=1cbf79627fba92acaf714248125581f76f0c8da7094981d913e8d12923e7c5f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/77/2c/c1a518cb72ec9aa07f4a7cdfcd933be54a8575d837e732f7f1\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: Werkzeug, websocket-client, urllib3, tabulate, sqlparse, smmap, querystring-parser, pyyaml, pyjwt, protobuf, prometheus-client, oauthlib, itsdangerous, importlib-resources, importlib-metadata, gunicorn, greenlet, cloudpickle, sqlalchemy, Mako, gitdb, gitpython, Flask, docker, databricks-cli, alembic, prometheus-flask-exporter, mlflow\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.2\n",
      "    Uninstalling urllib3-2.0.2:\n",
      "      Successfully uninstalled urllib3-2.0.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.6.0\n",
      "    Uninstalling importlib-metadata-6.6.0:\n",
      "      Successfully uninstalled importlib-metadata-6.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 5.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-2.2.5 Mako-1.2.4 Werkzeug-2.2.3 alembic-1.11.1 cloudpickle-2.2.1 databricks-cli-0.17.7 docker-6.1.2 gitdb-4.0.10 gitpython-3.1.31 greenlet-2.0.2 gunicorn-20.1.0 importlib-metadata-5.2.0 importlib-resources-5.12.0 itsdangerous-2.1.2 mlflow-1.30.1 oauthlib-3.2.2 prometheus-client-0.17.0 prometheus-flask-exporter-0.22.4 protobuf-4.23.2 pyjwt-2.7.0 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 sqlalchemy-1.4.48 sqlparse-0.4.4 tabulate-0.9.0 urllib3-1.26.16 websocket-client-1.5.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT =\"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data(housing_path=HOUSING_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Mlflow server"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://localhost:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/16 14:13:03 INFO mlflow.tracking.fluent: Experiment with name 'ElasticNet_house' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlruns/158930113435695454', creation_time=1673858589900, experiment_id='158930113435695454', last_update_time=1673858589900, lifecycle_stage='active', name='ElasticNet_house', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"ElasticNet_house\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mlflow tracking parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:,households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household,population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household,population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('attribs_adder', CombinedAttributesAdder()),('std_scaler', StandardScaler()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    housing = load_housing_data(housing_path=HOUSING_PATH)\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2,random_state=42)\n",
    "    \n",
    "    with mlflow.start_run(run_name='Main') as parent_run:\n",
    "        mlflow.log_param(\"Main\", \"yes\")\n",
    "        split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,random_state=42)\n",
    "        \n",
    "        with mlflow.start_run(run_name='Data_Preparation', nested=True) as child_run:\n",
    "            mlflow.log_param(\"Data Preparayion\", \"yes\")\n",
    "    \n",
    "            housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],bins=[0., 1.5, 3.0, 4.5, 6., np.inf],labels=[1, 2, 3, 4, 5])\n",
    "    \n",
    "            for train_index, test_index in split.split(housing,housing[\"income_cat\"]):\n",
    "                strat_train_set = housing.loc[train_index]\n",
    "                strat_test_set = housing.loc[test_index]\n",
    "        \n",
    "            for set_ in (strat_train_set, strat_test_set):\n",
    "                set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "        \n",
    "            housing = strat_train_set.copy()\n",
    "    \n",
    "            housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "            housing[\"bedrooms_per_room\"] =housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "            housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "    \n",
    "            housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "            housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "    \n",
    "            median = housing[\"total_bedrooms\"].median() # option 3\n",
    "            housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "    \n",
    "    \n",
    "            imputer = SimpleImputer(strategy=\"median\")\n",
    "    \n",
    "            housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "    \n",
    "            imputer.fit(housing_num)\n",
    "    \n",
    "            X = imputer.transform(housing_num)\n",
    "    \n",
    "            housing_tr = pd.DataFrame(X, columns=housing_num.columns,index=housing_num.index)\n",
    "    \n",
    "            housing_cat = housing[[\"ocean_proximity\"]]\n",
    "    \n",
    "            ordinal_encoder = OrdinalEncoder()\n",
    "            housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "    \n",
    "            cat_encoder = OneHotEncoder()\n",
    "            housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "    \n",
    "    \n",
    "    \n",
    "            attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "            housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "    \n",
    "            housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "    \n",
    "            num_attribs = list(housing_num)\n",
    "            cat_attribs = [\"ocean_proximity\"]\n",
    "    \n",
    "            full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs),\n",
    "                (\"cat\", OneHotEncoder(), cat_attribs),])\n",
    "        \n",
    "            housing_prepared = full_pipeline.fit_transform(housing)\n",
    "            \n",
    "        with mlflow.start_run(run_name='Model_Training', nested=True) as child_run:\n",
    "            mlflow.log_param(\"Model Training\", \"yes\")\n",
    "    \n",
    "            lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "            lr.fit(housing_prepared, housing_labels)\n",
    "    \n",
    "            predicted_qualities = lr.predict(housing_prepared)\n",
    "            (rmse, mae, r2) = eval_metrics(housing_labels, predicted_qualities)\n",
    "        \n",
    "        with mlflow.start_run(run_name='Model_Performance', nested=True) as child_run:\n",
    "            mlflow.log_param(\"Model Performance\", \"yes\")\n",
    "            print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "            print(\"  RMSE: %s\" % rmse)\n",
    "            print(\"  MAE: %s\" % mae)\n",
    "            print(\"  R2: %s\" % r2)\n",
    "    \n",
    "            mlflow.log_param(key=\"alpha\", value=alpha)\n",
    "            mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\n",
    "            mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "            mlflow.log_artifact('datasets')\n",
    "            print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "            mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 73689.95546046467\n",
      "  MAE: 54624.63812598483\n",
      "  R2: 0.59433603239391\n",
      "Save to: mlruns/158930113435695454/bb7df96da8d149aeadfb6bc0b3eb2a8f/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.200000, l1_ratio=0.200000):\n",
      "  RMSE: 71734.82432989801\n",
      "  MAE: 52579.03875426437\n",
      "  R2: 0.6155765038209369\n",
      "Save to: mlruns/158930113435695454/0a1dc352e2e3414f8cb915f8bf4c4744/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.2, 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
